# mm_run.py
# 
# The main script that runs MultiMoon
# Darin Ragozzine
# March 27, 2020
#
# Run with 
# python mm_run.py args
# where args are some combination of input and output file names TBD



# - Input: filename that is a JSON text file version of run_props dictionary
# - Output: directly, information about the success of the run
# - Output: indirectly: posterior, plots, etc.

#Works with run_props dictionary
# - Reads in run_props dictionary (from JSON)
# - Adds information autogenerated for this specific run
# - Checks other information

#Generates Initial Guess
#Make param_to_fit_scale: a parameters dataframe with the scale we'll use for converting to the fit values
#default: param_to_fit_scale is the first row of the init_guess dataframe
# - that way, every system and every parameter is pretty naturally scaled automatically!

#Checks if geocentric_object_position.csv already exists; if not, creates it; then reads it in and stores it #somewhere global

#Opens obsdata file and puts it into dataframe and stores it somewhere global

#Initializes Run
#Chooses prior and likelihood methods

#Runs emcee

#Takes posterior from emcee, thins, converts from fit_array to posterior dataframe in parameter format
#Saves posterior dataframe to designated output file

#Makes requested plots


"""Run MultiMoon

Inputs:
	filename that is a JSON text file version of run_props dictionary

Outputs:
	diagnostic information about the run

"""

import sys
import os
import emcee
import numpy as np
import pandas as pd
import mm_runprops
import mm_init_guess
import mm_likelihood
import mm_make_geo_pos
import mm_priors
import mm_relast
import mm_analysis


# Read in the run props dictionary
# Adds information autogenerated for this specific run
# Checks other information
runprops = mm_runprops.runprops
walkers = runprops.get("nwalkers")

#ndim is equal to the number of dimension, should this be equal to the length of the parameter array?
ndim = 1

# Generate the intial guess for emcee
guesses = mm_init_guess.mm_init_guess(runprops, walkers)	# maybe more args

# Convert the guesses into fitting units and place in numpy array
p0 = np.zeros((ndim, walkers))
for i in range(ndim):
	p0[i,:] = guesses[i+1,:]

# Check to see if geocentric_object_position.csv exists and if not creates it
objname = runprops.get('objectname')
if os.path.exists("geocentric_" + objname + "_position.csv"):
	print("Object geocentric position file geocentric_" + objname + "_position.csv will be used")
else:
	print("No object geocentric position file exists. Creating new file.")
	mm_make_geo_pos.mm_make_geo_pos(objname, start='2000-01-01', end='2040-01-01', step='10d')	# This is basically a function based on DS's makeHorFile
	print("geocentric_" + objname + "_position.csv has been created")


geocentric_object_positions = pd.read_csv("geocentric_" + objname + "_position.csv")

# Now get observations data frame
#'../data/HaumeaObsDf.csv'

obsdata = "../data/" + objname + "/HaumeaObsDF.csv"
if os.path.exists(obsdata):
	print("Observational data file " + obsdata + " will be used")
else:
	print("ERROR: No observational data file exists. Aborting run.")
	sys.exit()
	# Could change this to create a data file given the correct information,
	# but for now I'm just aborting the run

# Should we input a loop to test all walers to see if the return non-inf probabilities?
# Doing this will really cut down the time for convergence since walkers aren't "blindly"
# walking around in bad parameter space. 
#The only problem might be that it takes a long time to test all of p0? Might be worth it

reset = 0

for i in range(walkers):
	llhood = mm_likelihood.mm_likelihood(p0[:,i]) # add additional args if needs be
	while (reset < 500) & (llhood == -np.Inf):
		if (reset % 500 == 0) & (reset != 0):
			print("ERROR: Initial guesses for walkers may be bad.")
			abort = input("Abort script? (yes/no) ")
			while abort != "yes" & abort != "no":
				print("Invalid input")
				abort = input("Abort script? (yes/no) ")
			if abort == "yes":
				sys.exit()
		# reset parameter values for that walker
		llhood = mm_likelihood.mm_likelihood(p0[:,i])
		reset += 1
        
# Now creating the sampler object
#You will pass some args int mm_likelihood, like the fit_array.
sampler = emcee.EnsembleSampler(walkers, ndim, mm_likelihood.log_probability, args = None)

#Is this correct? I'm not sure
nburnin = runprops.get("nburnin")
#Starting the burnin
p0 = np.transpose(p0)
print(p0.shape)

state = sampler.run_mcmc(p0, nburnin)
sampler.reset()

nsteps = runprops.get("nsteps")

# Now do the full run with the leftovers of the burnin
sampler.run_mcmc(state, nsteps);

# Once it's completed, we need to save the chain
chain = sampler.get_chain(thin = runprops.get("nthinning"))
flatchain = sampler.get_chain(flat = True, thin = runprops.get("nthinning"))
# save chains

mm_analysis.mm_analysis(sampler,obsdata)