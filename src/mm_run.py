# mm_run.py
# 
# The main script that runs MultiMoon
# Darin Ragozzine
# March 27, 2020
#
# Run with 
# python mm_run.py args
# where args are some combination of input and output file names TBD



# - Input: filename that is a JSON text file version of run_props dictionary
# - Output: directly, information about the success of the run
# - Output: indirectly: posterior, plots, etc.

#Works with run_props dictionary
# - Reads in run_props dictionary (from JSON)
# - Adds information autogenerated for this specific run
# - Checks other information

#Generates Initial Guess
#Make param_to_fit_scale: a parameters dataframe with the scale we'll use for converting to the fit values
#default: param_to_fit_scale is the first row of the init_guess dataframe
# - that way, every system and every parameter is pretty naturally scaled automatically!

#Checks if geocentric_object_position.csv already exists; if not, creates it; then reads it in and stores it #somewhere global

#Opens obsdata file and puts it into dataframe and stores it somewhere global

#Initializes Run
#Chooses prior and likelihood methods

#Runs emcee

#Takes posterior from emcee, thins, converts from fit_array to posterior dataframe in parameter format
#Saves posterior dataframe to designated output file

#Makes requested plots


"""Run MultiMoon

Inputs:
	filename that is a JSON text file version of run_props dictionary

Outputs:
	diagnostic information about the run

"""

import sys
import numpy as np
import pandas as pd
import mm_runprops.py
import mm_init_guess.py
import mm_likelihood.py
import mm_make_geo_pos.py
import mm_priors.py
import mm_relast.py


# Read in the run props dictionary
# Adds information autogenerated for this specific run
# Checks other information

walkers = runprops.get("nwalkers")

#ndim is equal to the numer of dimension, should this be equal to the length of the parameter array?
ndim = 1

# Generate the intial guess for emcee
guesses = mm_init_guess(run_props, walkers)	# maybe more args

# Convert the guesses into fitting units and place in numpy array
p0 = np.zeros((ndim, walkers))
for i in range(ndim):
	p0[i,:] = guesses[i+1,:]

# Check to see if geocentric_object_position.csv exists and if not creates it
if os.path.exists("geocentric_" + objname + "_position.csv"):
	print("Object geocentric position file geocentric_" + objname + "_position.csv will be used")
else:
	print("No object geocentric position file exists. Creating new file.")
	mm_make_geo_pos(objname, start='2000-01-01', end='2040-01-01', step='10d')	# This is basically a function based on DS's makeHorFile
	print("geocentric_" + objname + "_position.csv has been created")


geocentric_object_positions = pd.read_csv("geocentric_" + objname + "_position.csv")

# Now get observations data frame
if os.path.exists(obsdata):
	print("Observational data file " + obsdata + " will be used")
else:
	print("ERROR: No observational data file exists. Aborting run.")
	sys.exit()
	# Could change this to create a data file given the correct information,
	# but for now I'm just aborting the run

# Should we input a loop to test all walers to see if the return non-inf probabilities?
# Doing this will really cut down the time for convergence since walkers aren't "blindly"
# walking around in bad parameter space. 
#The only problem might be that it takes a long time to test all of p0? Might be worth it

reset = 0

for i in range(walkers):
	llhood = mm_likelihood(p0[:,i]) # add additional args if needs be
	while (reset < 500) & (llhood == -np.Inf):
		if (reset % 500 == 0) & (reset != 0):
			print("ERROR: Initial guesses for walkers may be bad.")
			abort = input("Abort script? (yes/no) ")
			while abort != "yes" & abort != "no":
				print("Invalid input")
				abort = input("Abort script? (yes/no) ")
			if abort == "yes":
				sys.exit()
		# reset parameter values for that walker
		llhood = mm_likelihood(p0[:,i])
		reset += 1
        
# Now creating the sampler object
sampler = emcee.EnsembleSampler(walkers, ndim, mm_likelihood, args = )

#Is this correct? I'm not sure
nburnin = runprops.get("nthinning")
#Starting the burnin
state = sampler.run_mcmc(p0, nburnin)
sampler.reset()

nsteps = runprops.get("nsteps")

# Now do the full run with the leftovers of the burnin
sampler.run_mcmc(state, nsteps);

# Once it's completed, we need to save the chain
chain = sampler.get_chain()
flatchain = sampler.get_chain(flat = True)
# save chains

"""
Function to convert the parameter dataframe to a scaled and fitted array.
Inputs: 
1) The Parameters dataframe
2) The fix/float/constrain constraints dictionary
3) The dictionary describing the scale of each element

Outputs:
1) The fitted array of parameters
2) The dictionary of the param fit data
"""
def from_param_df_to_fit_array(dataframe, contraints, param_to_fit_scale):
    
"""
Function to convert a fitted array into the parameter dataframe
Inputs: 
1) The fitted array
2) The fix/float/constrain constraints dictionary
3) The dictionary describing the scale of each element

Outputs:
1) Dataframe in parameter format
"""
def from_fit_array_to_param_df(fit_array, contraints, param_to_fit_scale):
    

